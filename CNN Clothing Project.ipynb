{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#Import necessary Libraries\n",
    "\n",
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 4us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 253s 10us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 0us/step\n",
      "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 28s 6us/step\n"
     ]
    }
   ],
   "source": [
    "# Load fashion MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples/observations in training data: 60000\n",
      "Number of labels in training data: 60000\n",
      "Dimensions of a single image in x_train:(28, 28)\n",
      "-------------------------------------------------------------\n",
      "Number of samples/observations in test data: 10000\n",
      "Number of labels in test data: 10000\n",
      "Dimensions of single image in x_test:(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "# Check the shape and size of x_train, x_test, y_train, y_test\n",
    "print (\"Number of samples/observations in training data: \" + str(len(x_train)))\n",
    "print (\"Number of labels in training data: \" + str(len(y_train)))\n",
    "print (\"Dimensions of a single image in x_train:\" + str(x_train[0].shape))\n",
    "print(\"-------------------------------------------------------------\")\n",
    "print (\"Number of samples/observations in test data: \" + str(len(x_test)))\n",
    "print (\"Number of labels in test data: \" + str(len(y_test)))\n",
    "print (\"Dimensions of single image in x_test:\" + str(x_test[0].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization library to visualize images \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting 5 images, Subplot arugments represent nrows, ncols and index\n",
    "# Color map is set to grey since our image dataset is grayscale\n",
    "plt.subplot(231)\n",
    "random_num = np.random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "plt.subplot(232)\n",
    "random_num = np.random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "plt.subplot(233)\n",
    "random_num = np.random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "plt.subplot(234)\n",
    "random_num = np.random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "plt.subplot(235)\n",
    "random_num = np.random.randint(0,len(x_train))\n",
    "plt.imshow(x_train[random_num], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "\n",
    "# Visualize the images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 26, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,200,778\n",
      "Trainable params: 1,200,330\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Import necessary keras specific libraries\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras import backend as K\n",
    "\n",
    "# Setting Training Parameters like batch_size, epochs\n",
    "batch_size = 128\n",
    "epochs = 100\n",
    "\n",
    "# Storing the number of rows and columns\n",
    "img_rows = x_train[0].shape[0]\n",
    "img_cols = x_train[1].shape[0]\n",
    "\n",
    "''' Getting the data in the right 'shape' as required by Keras i.e. adding a 4th \n",
    "dimension to our data thereby changing the original image shape of (60000,28,28) \n",
    "to (60000,28,28,1)'''\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# Storing the shape of a single image \n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Changing image type to float32 data type\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# Normalizing the data by changing the image pixel range from (0 to 255) to (0 to 1)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Performing one hot encoding\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "# Calculate the number of classes and number of pixels \n",
    "num_classes = y_test.shape[1]\n",
    "num_pixels = x_train.shape[1] * x_train.shape[2]\n",
    "\n",
    "# Create CNN model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = keras.optimizers.Adadelta(),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 210s 4ms/step - loss: 0.4436 - accuracy: 0.8450 - val_loss: 1.0387 - val_accuracy: 0.6098\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 173s 3ms/step - loss: 0.2896 - accuracy: 0.8967 - val_loss: 0.3090 - val_accuracy: 0.8922\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.2392 - accuracy: 0.9146 - val_loss: 0.2591 - val_accuracy: 0.9037\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.2119 - accuracy: 0.9236 - val_loss: 0.2335 - val_accuracy: 0.9160\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.1893 - accuracy: 0.9316 - val_loss: 0.2260 - val_accuracy: 0.9170\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.1725 - accuracy: 0.9385 - val_loss: 0.2269 - val_accuracy: 0.9186\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.1566 - accuracy: 0.9439 - val_loss: 0.2186 - val_accuracy: 0.9248\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 178s 3ms/step - loss: 0.1433 - accuracy: 0.9484 - val_loss: 0.2457 - val_accuracy: 0.9222\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 240s 4ms/step - loss: 0.1335 - accuracy: 0.9520 - val_loss: 0.2267 - val_accuracy: 0.9266\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 303s 5ms/step - loss: 0.1245 - accuracy: 0.9560 - val_loss: 0.2178 - val_accuracy: 0.9299\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 187s 3ms/step - loss: 0.1170 - accuracy: 0.9580 - val_loss: 0.2331 - val_accuracy: 0.9159\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 173s 3ms/step - loss: 0.1077 - accuracy: 0.9615 - val_loss: 0.2134 - val_accuracy: 0.9289\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.1001 - accuracy: 0.9643 - val_loss: 0.2179 - val_accuracy: 0.9273\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0960 - accuracy: 0.9649 - val_loss: 0.2243 - val_accuracy: 0.9287\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0877 - accuracy: 0.9682 - val_loss: 0.2236 - val_accuracy: 0.9299\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0855 - accuracy: 0.9695 - val_loss: 0.2639 - val_accuracy: 0.9319\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0844 - accuracy: 0.9698 - val_loss: 0.2247 - val_accuracy: 0.9289\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0775 - accuracy: 0.9726 - val_loss: 0.2619 - val_accuracy: 0.9308\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0738 - accuracy: 0.9735 - val_loss: 0.2504 - val_accuracy: 0.9338\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0742 - accuracy: 0.9731 - val_loss: 0.2731 - val_accuracy: 0.9344\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0679 - accuracy: 0.9754 - val_loss: 0.2336 - val_accuracy: 0.9305\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0638 - accuracy: 0.9772 - val_loss: 0.3319 - val_accuracy: 0.9293\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0640 - accuracy: 0.9771 - val_loss: 0.2543 - val_accuracy: 0.9343\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0637 - accuracy: 0.9769 - val_loss: 0.2659 - val_accuracy: 0.9332\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0616 - accuracy: 0.9779 - val_loss: 0.3115 - val_accuracy: 0.9301\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0564 - accuracy: 0.9799 - val_loss: 0.3327 - val_accuracy: 0.9356\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 166s 3ms/step - loss: 0.0567 - accuracy: 0.9792 - val_loss: 0.2864 - val_accuracy: 0.9305\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0549 - accuracy: 0.9799 - val_loss: 0.3270 - val_accuracy: 0.9281\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0524 - accuracy: 0.9811 - val_loss: 0.2651 - val_accuracy: 0.9311\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0502 - accuracy: 0.9819 - val_loss: 0.2627 - val_accuracy: 0.9334\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 167s 3ms/step - loss: 0.0508 - accuracy: 0.9817 - val_loss: 0.2823 - val_accuracy: 0.9317\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0465 - accuracy: 0.9829 - val_loss: 0.2958 - val_accuracy: 0.9365\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0460 - accuracy: 0.9835 - val_loss: 0.3082 - val_accuracy: 0.9335\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0472 - accuracy: 0.9831 - val_loss: 0.2921 - val_accuracy: 0.9307\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 0.2815 - val_accuracy: 0.9349\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0431 - accuracy: 0.9842 - val_loss: 0.4129 - val_accuracy: 0.9304\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 0.2546 - val_accuracy: 0.9314\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0451 - accuracy: 0.9840 - val_loss: 0.2828 - val_accuracy: 0.9334\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 170s 3ms/step - loss: 0.0422 - accuracy: 0.9847 - val_loss: 0.3503 - val_accuracy: 0.9351\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0387 - accuracy: 0.9862 - val_loss: 0.3821 - val_accuracy: 0.9332\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0405 - accuracy: 0.9853 - val_loss: 0.3331 - val_accuracy: 0.9345\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0410 - accuracy: 0.9856 - val_loss: 0.2867 - val_accuracy: 0.9329\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0411 - accuracy: 0.9858 - val_loss: 0.3122 - val_accuracy: 0.9304\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0399 - accuracy: 0.9860 - val_loss: 0.3265 - val_accuracy: 0.9358\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 162s 3ms/step - loss: 0.0373 - accuracy: 0.9862 - val_loss: 0.2797 - val_accuracy: 0.9349\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0375 - accuracy: 0.9865 - val_loss: 0.3537 - val_accuracy: 0.9352\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0378 - accuracy: 0.9873 - val_loss: 0.2853 - val_accuracy: 0.9343\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0366 - accuracy: 0.9876 - val_loss: 0.2800 - val_accuracy: 0.9360\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.3922 - val_accuracy: 0.9350\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0368 - accuracy: 0.9877 - val_loss: 0.4736 - val_accuracy: 0.9331\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.2784 - val_accuracy: 0.9335\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0366 - accuracy: 0.9871 - val_loss: 0.2701 - val_accuracy: 0.9322\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0312 - accuracy: 0.9890 - val_loss: 0.3951 - val_accuracy: 0.9342\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 161s 3ms/step - loss: 0.0325 - accuracy: 0.9886 - val_loss: 0.3896 - val_accuracy: 0.9353\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0338 - accuracy: 0.9881 - val_loss: 0.4632 - val_accuracy: 0.9309\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0329 - accuracy: 0.9890 - val_loss: 0.5024 - val_accuracy: 0.9323\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0312 - accuracy: 0.9892 - val_loss: 0.3331 - val_accuracy: 0.9360\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0329 - accuracy: 0.9881 - val_loss: 0.3505 - val_accuracy: 0.9314\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0334 - accuracy: 0.9885 - val_loss: 0.2452 - val_accuracy: 0.9338\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.3474 - val_accuracy: 0.9332\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0289 - accuracy: 0.9899 - val_loss: 0.3602 - val_accuracy: 0.9342\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0305 - accuracy: 0.9897 - val_loss: 0.3376 - val_accuracy: 0.9345\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0308 - accuracy: 0.9894 - val_loss: 0.2827 - val_accuracy: 0.9320\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 165s 3ms/step - loss: 0.0301 - accuracy: 0.9897 - val_loss: 0.2704 - val_accuracy: 0.9324\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0291 - accuracy: 0.9901 - val_loss: 0.3286 - val_accuracy: 0.9336\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0288 - accuracy: 0.9898 - val_loss: 0.2867 - val_accuracy: 0.9314\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.3916 - val_accuracy: 0.9330\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0279 - accuracy: 0.9898 - val_loss: 0.3024 - val_accuracy: 0.9334\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0288 - accuracy: 0.9906 - val_loss: 0.4046 - val_accuracy: 0.9355\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0260 - accuracy: 0.9913 - val_loss: 0.5885 - val_accuracy: 0.9348\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 164s 3ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.2946 - val_accuracy: 0.9346\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 163s 3ms/step - loss: 0.0302 - accuracy: 0.9899 - val_loss: 0.3825 - val_accuracy: 0.9355\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 169s 3ms/step - loss: 0.0274 - accuracy: 0.9906 - val_loss: 0.5643 - val_accuracy: 0.9331\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0258 - accuracy: 0.9913 - val_loss: 0.3768 - val_accuracy: 0.9348\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0245 - accuracy: 0.9918 - val_loss: 0.2971 - val_accuracy: 0.9337\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0269 - accuracy: 0.9905 - val_loss: 0.3875 - val_accuracy: 0.9352\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.4425 - val_accuracy: 0.9380\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.4428 - val_accuracy: 0.9375\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0245 - accuracy: 0.9915 - val_loss: 0.4802 - val_accuracy: 0.9349\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0245 - accuracy: 0.9916 - val_loss: 0.3459 - val_accuracy: 0.9350\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0243 - accuracy: 0.9918 - val_loss: 0.4183 - val_accuracy: 0.9335\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0252 - accuracy: 0.9911 - val_loss: 0.3519 - val_accuracy: 0.9350\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.4769 - val_accuracy: 0.9349\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0258 - accuracy: 0.9909 - val_loss: 0.3384 - val_accuracy: 0.9338\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.3310 - val_accuracy: 0.9337\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.3300 - val_accuracy: 0.9343\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0241 - accuracy: 0.9914 - val_loss: 0.3283 - val_accuracy: 0.9319\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0251 - accuracy: 0.9909 - val_loss: 0.3436 - val_accuracy: 0.9329\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 160s 3ms/step - loss: 0.0254 - accuracy: 0.9909 - val_loss: 0.4041 - val_accuracy: 0.9351\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.4361 - val_accuracy: 0.9351\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 158s 3ms/step - loss: 0.0250 - accuracy: 0.9919 - val_loss: 0.6071 - val_accuracy: 0.9344\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0232 - accuracy: 0.9921 - val_loss: 0.3439 - val_accuracy: 0.9356\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0227 - accuracy: 0.9919 - val_loss: 0.4654 - val_accuracy: 0.9347\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.3863 - val_accuracy: 0.9349\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0219 - accuracy: 0.9925 - val_loss: 0.3023 - val_accuracy: 0.9360\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0207 - accuracy: 0.9929 - val_loss: 0.4420 - val_accuracy: 0.9331\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0222 - accuracy: 0.9923 - val_loss: 0.4508 - val_accuracy: 0.9332\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.4380 - val_accuracy: 0.9380\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.4975 - val_accuracy: 0.9384\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 159s 3ms/step - loss: 0.0233 - accuracy: 0.9920 - val_loss: 0.3170 - val_accuracy: 0.9354\n",
      "Test loss: 0.3170296280965209\n",
      "Test accuracy: 0.9354000091552734\n"
     ]
    }
   ],
   "source": [
    "model_fitting = model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model with the name clothing_classification_model\n",
    "model.save('clothing_classification_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
